import whisper
import srt
import datetime
import os
import subprocess
import tempfile
import gradio as gr

# === 1. åˆå§‹åŒ–æ¨¡å‹ (å…¨å±€åŠ è½½ä¸€æ¬¡ï¼Œå¯åŠ¨æ—¶åŠ è½½) ===
# å°†æ¨¡å‹åŠ è½½æ”¾åœ¨å…¨å±€ä½œç”¨åŸŸï¼Œè¿™æ ·Gradioç•Œé¢å¯åŠ¨æ—¶æ¨¡å‹å°±å·²åŠ è½½å¥½ï¼Œ
# é¿å…æ¯æ¬¡ç‚¹å‡»æŒ‰é’®éƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼Œå¤§å¤§æé«˜å“åº”é€Ÿåº¦ã€‚
print("="*50)
print("æ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...")
print("ğŸ§ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ (small)...")
try:
    # é»˜è®¤åŠ è½½ small æ¨¡å‹ï¼Œå¯ä»¥åœ¨ç•Œé¢ä¸Šæ›´æ”¹ï¼Œä½†é¢„åŠ è½½ä¸€ä¸ªå¯ä»¥åŠ å¿«é¦–æ¬¡å¤„ç†é€Ÿåº¦
    model = whisper.load_model("small")
    print("âœ… Whisper 'small' æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥ç¼“å­˜å·²åŠ è½½çš„æ¨¡å‹
    loaded_models = {"small": model}
except Exception as e:
    print(f"âŒ åŠ è½½é»˜è®¤ Whisper æ¨¡å‹å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£… PyTorch ä¸”æ”¯æŒ CUDA (å¦‚æœä½¿ç”¨GPU)ã€‚")
    loaded_models = {}
print("="*50)


# === 2. æ ¸å¿ƒå¤„ç†å‡½æ•° ===
# è¿™æ˜¯è„šæœ¬çš„æ ¸å¿ƒé€»è¾‘ï¼Œè¢«Gradioç•Œé¢è°ƒç”¨ã€‚
# ä½¿ç”¨ yield æ¥é€æ­¥è¿”å›æ—¥å¿—ä¿¡æ¯ï¼Œå®ç°æµå¼è¾“å‡ºã€‚
def process_videos(video_folder, language, model_size):
    """
    å¤„ç†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è§†é¢‘ï¼Œç”ŸæˆSRTå­—å¹•ã€‚
    
    Args:
        video_folder (str): åŒ…å«è§†é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        language (str): è§†é¢‘çš„è¯­è¨€ã€‚
        model_size (str): è¦ä½¿ç”¨çš„Whisperæ¨¡å‹å¤§å°ã€‚
        
    Yields:
        str: å¤„ç†è¿‡ç¨‹ä¸­çš„æ—¥å¿—ä¿¡æ¯ã€‚
    """
    log_messages = []
    
    # --- è¾“å…¥éªŒè¯ ---
    if not video_folder or not os.path.isdir(video_folder):
        yield "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚"
        return

    log_messages.append(f"ğŸ“‚ ç›®æ ‡æ–‡ä»¶å¤¹: {video_folder}")
    log_messages.append(f"ğŸŒ è¯†åˆ«è¯­è¨€: {language}")
    log_messages.append(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: {model_size}")
    yield "\n".join(log_messages)

    # --- æ¨¡å‹åŠ è½½/åˆ‡æ¢ ---
    # æ£€æŸ¥å½“å‰é€‰æ‹©çš„æ¨¡å‹æ˜¯å¦å·²ç»åŠ è½½ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™åŠ è½½å®ƒ
    if model_size not in loaded_models:
        try:
            log_messages.append(f"\n modeli æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ '{model_size}'...")
            yield "\n".join(log_messages)
            
            new_model = whisper.load_model(model_size)
            loaded_models[model_size] = new_model
            
            log_messages.append(f"âœ… æ¨¡å‹ '{model_size}' åŠ è½½æˆåŠŸã€‚")
            yield "\n".join(log_messages)
        except Exception as e:
            log_messages.append(f"âŒ åŠ è½½ Whisper æ¨¡å‹ '{model_size}' å¤±è´¥: {e}")
            yield "\n".join(log_messages)
            return
            
    # è·å–å½“å‰è¦ä½¿ç”¨çš„æ¨¡å‹
    current_model = loaded_models[model_size]

    # --- æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶ ---
    supported_extensions = ['.mp4', '.mkv', '.ts', '.avi', '.mov', '.flv', '.webm']
    video_files = [f for f in os.listdir(video_folder)
                   if os.path.isfile(os.path.join(video_folder, f)) and os.path.splitext(f)[1].lower() in supported_extensions]

    if not video_files:
        log_messages.append("\nâŒ åœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•æ”¯æŒçš„è§†é¢‘æ–‡ä»¶ã€‚")
        yield "\n".join(log_messages)
        return

    log_messages.append(f"\nâ–¶ï¸ å‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹å¤„ç†...")
    yield "\n".join(log_messages)

    # --- å¾ªç¯å¤„ç† ---
    for index, video_name in enumerate(video_files):
        video_path = os.path.join(video_folder, video_name)
        output_srt = os.path.splitext(video_path)[0] + ".srt"

        log_messages.append("\n" + "-"*40)
        log_messages.append(f"ğŸ¬ ({index + 1}/{len(video_files)}) å¼€å§‹å¤„ç†: {video_name}")
        yield "\n".join(log_messages)

        if os.path.exists(output_srt):
            log_messages.append(f"ğŸŸ¡ å­—å¹•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè‡ªåŠ¨è·³è¿‡ã€‚")
            yield "\n".join(log_messages)
            continue

        # Step A: æå–éŸ³é¢‘
        audio_path = None
        try:
            log_messages.append("  - æ­£åœ¨æå–éŸ³é¢‘...")
            yield "\n".join(log_messages)
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_audio:
                audio_path = tmp_audio.name

            subprocess.run([
                "ffmpeg", "-y", "-i", video_path,
                "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path
            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except Exception as e:
            log_messages.append(f"  - âŒ æå–éŸ³é¢‘å¤±è´¥: {e}ã€‚è¯·ç¡®ä¿ ffmpeg å·²æ­£ç¡®å®‰è£…ã€‚")
            yield "\n".join(log_messages)
            if audio_path and os.path.exists(audio_path): os.remove(audio_path)
            continue
        
        # Step B: è¯­éŸ³è¯†åˆ«
        try:
            log_messages.append("  - æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
            yield "\n".join(log_messages)
            
            result = current_model.transcribe(audio_path, language=language, task="transcribe", fp16=False)
            segments = result["segments"]
        except Exception as e:
            log_messages.append(f"  - âŒ Whisper è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            yield "\n".join(log_messages)
            if audio_path and os.path.exists(audio_path): os.remove(audio_path)
            continue

        # Step C: ç”Ÿæˆå¹¶ä¿å­˜å­—å¹•
        log_messages.append("  - æ­£åœ¨ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶...")
        yield "\n".join(log_messages)
        
        subs = []
        for seg in segments:
            if text := seg["text"].strip():
                start_time = datetime.timedelta(seconds=seg["start"])
                end_time = datetime.timedelta(seconds=seg["end"])
                subs.append(srt.Subtitle(index=len(subs) + 1, start=start_time, end=end_time, content=text))
        
        try:
            with open(output_srt, "w", encoding="utf-8") as f:
                f.write(srt.compose(subs))
            log_messages.append(f"  - âœ… å­—å¹•å·²ä¿å­˜åˆ°: {os.path.basename(output_srt)}")
            yield "\n".join(log_messages)
        except Exception as e:
            log_messages.append(f"  - âŒ ä¿å­˜å­—å¹•æ–‡ä»¶å¤±è´¥: {e}")
            yield "\n".join(log_messages)
        
        finally:
             if audio_path and os.path.exists(audio_path): os.remove(audio_path)

    log_messages.append("\n" + "="*40)
    log_messages.append("ğŸ‰ æ‰€æœ‰è§†é¢‘æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼")
    yield "\n".join(log_messages)


# === 3. Gradio ç•Œé¢å®šä¹‰ ===
# Whisperæ”¯æŒçš„è¯­è¨€åˆ—è¡¨ (éƒ¨åˆ†å¸¸ç”¨)
# æ ¼å¼ä¸º [æ˜¾ç¤ºåç§°, Whisperå‚æ•°å€¼]
supported_languages = [
    ("Japanese", "Japanese"),
    ("English", "English"),
    ("Chinese", "Chinese"),
    ("Korean", "Korean"),
    ("French", "French"),
    ("German", "German"),
    ("Spanish", "Spanish"),
    ("Russian", "Russian"),
    ("Auto Detect", None) # None ä¼šè®© Whisper è‡ªåŠ¨æ£€æµ‹
]

# Whisper æ¨¡å‹å°ºå¯¸
model_sizes = ["tiny", "base", "small", "medium", "large"]

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # è§†é¢‘æ‰¹é‡å­—å¹•ç”Ÿæˆå·¥å…· (Whisper)
        è¾“å…¥ä¸€ä¸ªåŒ…å«è§†é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé€‰æ‹©è§†é¢‘çš„è¯­è¨€å’Œè¯†åˆ«æ¨¡å‹ï¼Œç‚¹å‡»â€œå¼€å§‹å¤„ç†â€å³å¯ä¸ºæ–‡ä»¶å¤¹å†…æ‰€æœ‰è§†é¢‘ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶ã€‚
        """
    )
    
    with gr.Row():
        folder_input = gr.Textbox(
            label="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„", 
            placeholder="ä¾‹å¦‚: D:\\Videos\\MySeries"
        )
    
    with gr.Row():
        lang_input = gr.Dropdown(
            choices=[lang[0] for lang in supported_languages],
            value="Japanese",
            label="è§†é¢‘è¯­è¨€"
        )
        model_input = gr.Dropdown(
            choices=model_sizes,
            value="small",
            label="Whisper æ¨¡å‹å¤§å°"
        )
    
    start_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
    
    log_output = gr.Textbox(
        label="å¤„ç†æ—¥å¿—", 
        lines=15, 
        interactive=False,
        autoscroll=True
    )
    
    # æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    def on_submit(folder, lang_display_name, model):
        # å°†æ˜¾ç¤ºåç§°è½¬æ¢ä¸ºWhisperéœ€è¦çš„å‚æ•°å€¼
        lang_value = next((val for name, val in supported_languages if name == lang_display_name), None)
        
        # ã€ã€ã€ è¿™æ˜¯å…³é”®ä¿®æ”¹ ã€‘ã€‘ã€‘
        # ä½¿ç”¨ yield from å°† process_videos ç”Ÿæˆå™¨äº§å‡ºçš„å†…å®¹ç›´æ¥è½¬äº¤ç»™ Gradio
        yield from process_videos(folder, lang_value, model)

    start_button.click(
        fn=on_submit,
        inputs=[folder_input, lang_input, model_input],
        outputs=[log_output]
    )

# === 4. å¯åŠ¨ç•Œé¢ ===
if __name__ == "__main__":
    # ä½¿ç”¨ share=True ä¼šç”Ÿæˆä¸€ä¸ªå…¬ç½‘é“¾æ¥ï¼Œæ–¹ä¾¿åˆ†äº«ç»™åˆ«äººä½¿ç”¨
    demo.launch()